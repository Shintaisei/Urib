import os
from pathlib import Path
import pandas as pd
import streamlit as st
import altair as alt
from typing import Optional
import re
import datetime as dt

# Paths
ROOT = Path(__file__).resolve().parent
EXPORT_DIR = ROOT / "data_exports" / "latest"
AGG_DIR = EXPORT_DIR / "aggregated"

@st.cache_data(show_spinner=False)
def load_csv(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    try:
        return pd.read_csv(path)
    except Exception:
        return pd.DataFrame()

def to_numeric(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0)
    return df

def bar(df: pd.DataFrame, x: str, y: str, title: str = "", top_n: Optional[int] = None):
    if df.empty or x not in df.columns or y not in df.columns:
        return None
    data = df.copy()
    data = to_numeric(data, [y])
    if top_n:
        data = data.sort_values(y, ascending=False).head(top_n)
    chart = alt.Chart(data).mark_bar().encode(
        x=alt.X(x + ":N", sort='-y', title=x),
        y=alt.Y(y + ":Q", title=y),
        tooltip=list(data.columns),
    ).properties(title=title, height=260)
    return chart

def ensure_dirs() -> None:
    EXPORT_DIR.mkdir(parents=True, exist_ok=True)
    AGG_DIR.mkdir(parents=True, exist_ok=True)

def run_fetch() -> None:
    from fetch_and_aggregate import main as fetch_main
    fetch_main()

ADMIN_EMAIL_RE = re.compile(r'^(master|mster)(00|0?[1-9]|[1-2][0-9]|30)@', re.IGNORECASE)

def is_admin_email(email: str) -> bool:
    if not isinstance(email, str):
        return False
    return ADMIN_EMAIL_RE.match(email.strip()) is not None

def normalize_email(value: str) -> str:
    """
    ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã®æ­£è¦åŒ–:
    - å‰å¾Œç©ºç™½é™¤å»ã€å…¨å°æ–‡å­—åŒ–
    - Gmail/Googlemail/icloud ã¯ +ä»¥é™ã‚’é™¤å»ï¼ˆã‚µãƒ–ã‚¢ãƒ‰ãƒ¬ã‚¹ç„¡è¦–ï¼‰
    - Gmail/Googlemail ã¯ local ã®ãƒ‰ãƒƒãƒˆã‚’ç„¡è¦–ã—ã€googlemail ã‚’ gmail ã«çµ±ä¸€
    """
    if not isinstance(value, str):
        return ""
    s = value.strip().lower()
    if "@" not in s:
        return s
    local, domain = s.split("@", 1)
    if domain in ("googlemail.com",):
        domain = "gmail.com"
    if domain in ("gmail.com", "googlemail.com", "icloud.com"):
        if "+" in local:
            local = local.split("+", 1)[0]
    if domain in ("gmail.com", "googlemail.com"):
        local = local.replace(".", "")
    return f"{local}@{domain}"

def admin_group(email: str) -> Optional[str]:
    """
    master/msterXX ã® XX ã‚’ 1-10 / 11-20 / 21-30 ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    """
    if not isinstance(email, str):
        return None
    m = ADMIN_EMAIL_RE.match(email.strip())
    if not m:
        return None
    # æœ«å°¾ã®æ•°å­—ï¼ˆå…ˆé ­ã‚¼ãƒ­è¨±å®¹ï¼‰
    digits = re.findall(r'(\d+)', email)
    if not digits:
        return None
    try:
        n = int(digits[0])
    except Exception:
        return None
    if 1 <= n <= 10:
        return "1-10"
    if 11 <= n <= 20:
        return "11-20"
    if 21 <= n <= 30:
        return "21-30"
    return None

def parse_date(col: pd.Series) -> pd.Series:
    return pd.to_datetime(col, errors="coerce").dt.tz_localize(None) if str(col.dtype) == "object" else pd.to_datetime(col, errors="coerce").dt.tz_localize(None)

def last_ndays_filter(df: pd.DataFrame, date_col: str, days: int = 30) -> pd.DataFrame:
    if df.empty or date_col not in df.columns:
        return df
    d = parse_date(df[date_col])
    cutoff = pd.Timestamp.now() - pd.Timedelta(days=days)
    return df.loc[d >= cutoff].assign(**{date_col: d})

def line(df: pd.DataFrame, x: str, y: str, color: Optional[str] = None, title: str = ""):
    if df.empty or x not in df.columns or y not in df.columns:
        return None
    enc = {
        "x": alt.X(f"{x}:T", title=x),
        "y": alt.Y(f"{y}:Q", title=y),
        "tooltip": list(df.columns),
    }
    if color and color in df.columns:
        enc["color"] = alt.Color(f"{color}:N", title=color)
    chart = alt.Chart(df).mark_line(point=True).encode(**enc).properties(title=title, height=260)
    return chart

def overview_tab():
    st.subheader("æ¦‚è¦")
    users_full = load_csv(AGG_DIR / "users_full_summary.csv")
    pv = load_csv(AGG_DIR / "pageviews_by_user.csv")
    boards = load_csv(AGG_DIR / "boards_summary.csv")
    market = load_csv(AGG_DIR / "market_summary.csv")
    # raw for trends
    posts_raw = load_csv(EXPORT_DIR / "board_posts.csv")
    replies_raw = load_csv(EXPORT_DIR / "board_replies.csv")

    # ç®¡ç†è€…ã‚’é™¤å¤–ã—ãŸãƒ“ãƒ¥ãƒ¼
    uf_non_admin = users_full[~users_full["email"].astype(str).apply(is_admin_email)] if not users_full.empty else users_full
    pv_non_admin = pv[~pv["email"].astype(str).apply(is_admin_email)] if not pv.empty else pv
    market_non_admin = market[~market["email"].astype(str).apply(is_admin_email)] if not market.empty else market

    cols = st.columns(4)
    with cols[0]:
        st.metric("ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°(é›†è¨ˆè¡Œ)", f"{len(uf_non_admin):,}")
    with cols[1]:
        total_posts = int(uf_non_admin.get("board_posts", pd.Series()).sum()) if not uf_non_admin.empty else 0
        st.metric("æ²ç¤ºæ¿æŠ•ç¨¿æ•°(ç·è¨ˆ)", f"{total_posts:,}")
    with cols[2]:
        act_30d = int(pv_non_admin.get("active_days_30d", pd.Series()).sum()) if not pv_non_admin.empty else 0
        st.metric("å»¶ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ—¥æ•°(30d)", f"{act_30d:,}")
    with cols[3]:
        m_items = int(market_non_admin.get("items", pd.Series()).sum()) if not market_non_admin.empty else 0
        st.metric("å‡ºå“æ•°(ç·è¨ˆ)", f"{m_items:,}")

    if not uf_non_admin.empty:
        left, right = st.columns(2)
        with left:
            st.markdown("#### æ²ç¤ºæ¿æŠ•ç¨¿ ä¸Šä½")
            chart = bar(uf_non_admin[["email","board_posts"]], x="email", y="board_posts", title="Top Posters", top_n=15)
            if chart is not None:
                st.altair_chart(chart, use_container_width=True)
        with right:
            st.markdown("#### ç›´è¿‘30æ—¥ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ—¥æ•° ä¸Šä½")
            if not pv_non_admin.empty:
                chart = bar(pv_non_admin[["email","active_days_30d"]], x="email", y="active_days_30d", title="Active Days (30d) Top", top_n=15)
                if chart is not None:
                    st.altair_chart(chart, use_container_width=True)

    # ãƒˆãƒ¬ãƒ³ãƒ‰: ç›´è¿‘30æ—¥ã®æŠ•ç¨¿/è¿”ä¿¡ æ¨ç§»
    with st.expander("ç›´è¿‘30æ—¥ã®æŠ•ç¨¿/è¿”ä¿¡ãƒˆãƒ¬ãƒ³ãƒ‰", expanded=True):
        n_days = st.slider("æœŸé–“(æ—¥)", 7, 90, 30, key="ov_trend_days")
        p30 = last_ndays_filter(posts_raw, "created_at", n_days)
        r30 = last_ndays_filter(replies_raw, "created_at", n_days)
        if not p30.empty or not r30.empty:
            pser = p30.assign(date=parse_date(p30["created_at"]).dt.date).groupby("date").size().reset_index(name="posts")
            rser = r30.assign(date=parse_date(r30["created_at"]).dt.date).groupby("date").size().reset_index(name="replies")
            trend = pd.merge(pser, rser, on="date", how="outer").fillna(0).sort_values("date")
            trend_long = trend.melt(id_vars=["date"], var_name="type", value_name="count")
            c = alt.Chart(trend_long).mark_line(point=True).encode(
                x=alt.X("date:T", title="æ—¥ä»˜"),
                y=alt.Y("count:Q", title="ä»¶æ•°"),
                color=alt.Color("type:N", title="ç¨®åˆ¥"),
                tooltip=list(trend_long.columns),
            ).properties(height=260)
            st.altair_chart(c, use_container_width=True)

    if not boards.empty:
        st.markdown("#### æ²ç¤ºæ¿åˆ¥ã®æ´»å‹•é‡")
        boards = to_numeric(boards, ["post_count","reply_count","post_likes","reply_likes","unique_visitors","unique_posters"])
        tabs = st.tabs(["æŠ•ç¨¿æ•°", "è¿”ä¿¡æ•°", "æŠ•ç¨¿ã„ã„ã­", "è¿”ä¿¡ã„ã„ã­", "è¨ªå•è€…æ•°", "æŠ•ç¨¿è€…æ•°"])
        metrics = [
            ("post_count","æŠ•ç¨¿æ•°"),
            ("reply_count","è¿”ä¿¡æ•°"),
            ("post_likes","æŠ•ç¨¿ã„ã„ã­"),
            ("reply_likes","è¿”ä¿¡ã„ã„ã­"),
            ("unique_visitors","è¨ªå•è€…æ•°"),
            ("unique_posters","æŠ•ç¨¿è€…æ•°"),
        ]
        for i, (col, ttl) in enumerate(metrics):
            with tabs[i]:
                chart = alt.Chart(boards).mark_bar().encode(
                    x=alt.X("board_id:N", title="Board"),
                    y=alt.Y(f"{col}:Q", title=ttl),
                    tooltip=list(boards.columns),
                ).properties(height=260)
                st.altair_chart(chart, use_container_width=True)

def users_tab():
    st.subheader("ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ è¡Œå‹•ã‚µãƒãƒª")
    users_full = load_csv(AGG_DIR / "users_full_summary.csv")
    pv = load_csv(AGG_DIR / "pageviews_by_user.csv")
    if users_full.empty:
        st.info("users_full_summary.csv ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦é›†è¨ˆã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return
    # ç®¡ç†è€…é™¤å¤–
    users_full = users_full[~users_full["email"].astype(str).apply(is_admin_email)]
    pv = pv[~pv["email"].astype(str).apply(is_admin_email)] if not pv.empty else pv
    q = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿", "")
    df = users_full.copy()
    for c in df.columns:
        if c not in ("email",):
            try:
                df[c] = pd.to_numeric(df[c])
            except Exception:
                df[c] = pd.to_numeric(df[c], errors="coerce")
    if q:
        df = df[df["email"].astype(str).str.contains(q, case=False, na=False)]
    # è¿½åŠ ãƒãƒ£ãƒ¼ãƒˆ
    st.markdown("#### ä¸Šä½ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¯”è¼ƒï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰")
    left, right = st.columns(2)
    with left:
        chart = bar(df[["email","board_posts"]], x="email", y="board_posts", title="Board Posts Top", top_n=20)
        if chart is not None:
            st.altair_chart(chart, use_container_width=True)
    with right:
        if not pv.empty:
            chart = bar(pv[["email","active_days_30d"]], x="email", y="active_days_30d", title="Active Days (30d) Top", top_n=20)
            if chart is not None:
                st.altair_chart(chart, use_container_width=True)
    # ä¸‹éƒ¨ã«ãƒ‡ãƒ¼ã‚¿ä¸€è¦§
    with st.expander("ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆusers_full_summaryï¼‰", expanded=False):
        st.dataframe(df.sort_values("board_posts", ascending=False), use_container_width=True, height=420)

def boards_tab():
    st.subheader("æ²ç¤ºæ¿ é›†è¨ˆ")
    boards = load_csv(AGG_DIR / "boards_summary.csv")
    posts_raw = load_csv(EXPORT_DIR / "board_posts.csv")
    replies_raw = load_csv(EXPORT_DIR / "board_replies.csv")
    pv_raw = load_csv(EXPORT_DIR / "page_views.csv")
    if boards.empty:
        st.info("boards_summary.csv ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    # ã‚¹ã‚¿ãƒƒã‚¯æ£’ï¼ˆæŠ•ç¨¿+è¿”ä¿¡ï¼‰
    boards = to_numeric(boards, ["post_count", "reply_count"])
    stacked = boards.melt(id_vars=["board_id"], value_vars=["post_count","reply_count"], var_name="type", value_name="count")
    c = alt.Chart(stacked).mark_bar().encode(
        x=alt.X("board_id:N", title="Board"),
        y=alt.Y("count:Q", stack="zero", title="ä»¶æ•°"),
        color=alt.Color("type:N", title="ç¨®åˆ¥"),
        tooltip=list(stacked.columns),
    ).properties(title="æŠ•ç¨¿/è¿”ä¿¡ ã‚¹ã‚¿ãƒƒã‚¯", height=260)
    st.altair_chart(c, use_container_width=True)

    # ãƒœãƒ¼ãƒ‰åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
    with st.expander("æ²ç¤ºæ¿ã”ã¨ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆç›´è¿‘60æ—¥ï¼‰", expanded=True):
        board_sel = st.text_input("å¯¾è±¡ board_idï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šå¯ã€‚ç©ºã¯å…¨ä½“ï¼‰", "")
        days = st.slider("æœŸé–“(æ—¥)", 7, 120, 60, key="board_trend_days")
        p = last_ndays_filter(posts_raw, "created_at", days)
        r = last_ndays_filter(replies_raw, "created_at", days)
        if board_sel.strip():
            ids = [s.strip() for s in board_sel.split(",") if s.strip()]
            p = p[p["board_id"].astype(str).isin(ids)]
            # replies ã¯ post_idã‹ã‚‰board_idã‚’å¼•ã‘ãªã„ã®ã§å…¨ä½“å‚¾å‘ã¨ã—ã¦è¡¨ç¤º
        p["date"] = parse_date(p["created_at"]).dt.date
        p_ser = p.groupby(["board_id","date"]).size().reset_index(name="posts")
        p_ser = p_ser.rename(columns={"board_id":"Board"})
        if not p_ser.empty:
            c2 = alt.Chart(p_ser).mark_line(point=True).encode(
                x=alt.X("date:T", title="æ—¥ä»˜"),
                y=alt.Y("posts:Q", title="æŠ•ç¨¿æ•°"),
                color=alt.Color("Board:N", title="Board"),
                tooltip=list(p_ser.columns),
            ).properties(height=260)
            st.altair_chart(c2, use_container_width=True)
    # ãƒœãƒ¼ãƒ‰åˆ¥DAUï¼ˆãƒ‘ã‚¹ã‹ã‚‰æ¨å®šï¼‰
    if not pv_raw.empty:
        with st.expander("ãƒœãƒ¼ãƒ‰åˆ¥ DAUï¼ˆPageViewã®pathã‹ã‚‰æ¨å®šï¼‰", expanded=False):
            dfp = pv_raw.copy()
            dfp["email"] = dfp.get("email", "").astype(str).map(normalize_email)
            dfp = dfp[dfp["email"].str.contains("@", na=False)]
            dfp = dfp[~dfp["email"].apply(is_admin_email)]
            dfp["created_at"] = parse_date(dfp.get("created_at"))
            dfp = dfp.dropna(subset=["created_at"])
            # pathã‹ã‚‰ /board/<id> ã‚’æŠ½å‡º
            dfp["path"] = dfp.get("path", "").astype(str)
            dfp["board_id"] = dfp["path"].str.extract(r"/board/(\\d+)", expand=False)
            dfp = dfp.dropna(subset=["board_id"])
            dfp = dfp.assign(day=lambda d: d["created_at"].dt.date)
            dau_b = dfp.groupby(["board_id","day"])["email"].nunique().reset_index(name="dau")
            sel = st.multiselect("å¯¾è±¡Board", sorted(dau_b["board_id"].unique().tolist()), default=sorted(dau_b["board_id"].unique().tolist())[:3])
            if sel:
                dau_b = dau_b[dau_b["board_id"].isin(sel)]
            chart_b = alt.Chart(dau_b).mark_line(point=True).encode(
                x=alt.X("day:T", title="æ—¥ä»˜"),
                y=alt.Y("dau:Q", title="DAU"),
                color=alt.Color("board_id:N", title="Board"),
                tooltip=[alt.Tooltip("board_id:N", title="Board"),
                         alt.Tooltip("day:T", title="æ—¥ä»˜"),
                         alt.Tooltip("dau:Q", title="DAU")],
            ).properties(height=260)
            st.altair_chart(chart_b, use_container_width=True)
    # ä¸‹éƒ¨ã«ãƒ‡ãƒ¼ã‚¿ä¸€è¦§
    with st.expander("ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆboards_summaryï¼‰", expanded=False):
        st.dataframe(boards, use_container_width=True, height=420)

def market_tab():
    st.subheader("ãƒãƒ¼ã‚±ãƒƒãƒˆ é›†è¨ˆ")
    market = load_csv(AGG_DIR / "market_summary.csv")
    items_raw = load_csv(EXPORT_DIR / "market_items.csv")
    if market.empty:
        st.info("market_summary.csv ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    # ç®¡ç†è€…é™¤å¤–
    market = market[~market["email"].astype(str).apply(is_admin_email)]
    market = to_numeric(market, ["items","likes_given_items","likes_received_items"])
    st.markdown("#### å‡ºå“æ•° ä¸Šä½ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰")
    chart = bar(market[["email","items"]], x="email", y="items", title="Items by User", top_n=15)
    if chart is not None:
        st.altair_chart(chart, use_container_width=True)
    # ä¾¡æ ¼åˆ†å¸ƒã¨å‡ºå“æ¨ç§»
    with st.expander("ä¾¡æ ¼åˆ†å¸ƒ / å‡ºå“æ¨ç§»", expanded=True):
        if not items_raw.empty:
            items_raw["price"] = pd.to_numeric(items_raw.get("price", 0), errors="coerce").fillna(0)
            items_raw["date"] = parse_date(items_raw.get("created_at"))
            col1, col2 = st.columns(2)
            with col1:
                hist = alt.Chart(items_raw).mark_bar().encode(
                    x=alt.X("price:Q", bin=alt.Bin(maxbins=40), title="ä¾¡æ ¼"),
                    y=alt.Y("count()", title="ä»¶æ•°"),
                ).properties(height=260, title="ä¾¡æ ¼ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ")
                st.altair_chart(hist, use_container_width=True)
            with col2:
                daily = items_raw.dropna(subset=["date"]).assign(day=lambda d: d["date"].dt.date).groupby("day").size().reset_index(name="items")
                c3 = line(daily, x="day", y="items", title="å‡ºå“æ•°ï¼ˆæ¨ç§»ï¼‰")
                if c3 is not None:
                    st.altair_chart(c3, use_container_width=True)
    # ä¾¡æ ¼å¸¯Ã—ç¨®åˆ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    if not items_raw.empty:
        with st.expander("ä¾¡æ ¼å¸¯ Ã— ç¨®åˆ¥ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", expanded=False):
            items = items_raw.copy()
            items["type"] = items.get("type", "").fillna("unknown").astype(str)
            items["price"] = pd.to_numeric(items.get("price", 0), errors="coerce").fillna(0)
            bins = [0, 500, 1000, 2000, 5000, 10000, 20000, 9999999]
            labels = ["0-500", "500-1k", "1k-2k", "2k-5k", "5k-10k", "10k-20k", "20k+"]
            items["price_band"] = pd.cut(items["price"], bins=bins, labels=labels, include_lowest=True)
            # pandas ã® observed æ—¢å®šå€¤å¤‰æ›´ã¸ã®å¯¾å¿œ
            cross = items.groupby(["type","price_band"], observed=False).size().reset_index(name="count")
            heat = alt.Chart(cross).mark_rect().encode(
                x=alt.X("price_band:N", title="ä¾¡æ ¼å¸¯", sort=labels),
                y=alt.Y("type:N", title="ç¨®åˆ¥"),
                color=alt.Color("count:Q", title="ä»¶æ•°"),
                tooltip=[alt.Tooltip("type:N", title="ç¨®åˆ¥"),
                         alt.Tooltip("price_band:N", title="ä¾¡æ ¼å¸¯"),
                         alt.Tooltip("count:Q", title="ä»¶æ•°")],
            ).properties(height=240)
            st.altair_chart(heat, use_container_width=True)
    # ä¸‹éƒ¨ã«ãƒ‡ãƒ¼ã‚¿ä¸€è¦§
    with st.expander("ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆmarket_summaryï¼‰", expanded=False):
        st.dataframe(market.sort_values("items", ascending=False), use_container_width=True, height=420)

def engagement_tab():
    st.subheader("ç¶™ç¶šãƒ­ã‚°ã‚¤ãƒ³ (PageViews)")
    pv = load_csv(AGG_DIR / "pageviews_by_user.csv")
    pv_raw = load_csv(EXPORT_DIR / "page_views.csv")
    posts_raw = load_csv(EXPORT_DIR / "board_posts.csv")
    replies_raw = load_csv(EXPORT_DIR / "board_replies.csv")
    if pv.empty:
        st.info("pageviews_by_user.csv ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    # ç®¡ç†è€…é™¤å¤–
    pv = pv[~pv["email"].astype(str).apply(is_admin_email)]
    # page_views.csv ã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ç´ä»˜ã‘ã§å†é›†è¨ˆï¼ˆä¿¡é ¼æ€§å‘ä¸Šï¼‰
    pv_user = pd.DataFrame()
    if not pv_raw.empty:
        dfu = pv_raw.copy()
        dfu["email"] = dfu.get("email", "").astype(str).map(normalize_email)
        dfu = dfu[dfu["email"].str.contains("@", na=False)]
        dfu = dfu[~dfu["email"].apply(is_admin_email)]
        dfu["created_at"] = parse_date(dfu.get("created_at"))
        dfu = dfu.dropna(subset=["created_at"])
        dfu["day"] = dfu["created_at"].dt.date
        cutoff_30 = pd.Timestamp.now().date() - pd.Timedelta(days=30)
        cutoff_7 = pd.Timestamp.now().date() - pd.Timedelta(days=7)
        # åŸºæœ¬é›†è¨ˆ
        base = dfu.groupby("email").agg(
            pv_total=("email", "count"),
            first_seen=("created_at", "min"),
            last_seen=("created_at", "max"),
        ).reset_index()
        days_total = dfu.groupby(["email","day"]).size().reset_index(name="pv").groupby("email")["day"].nunique().reset_index(name="active_days_total")
        days_30 = dfu[dfu["day"] >= cutoff_30].groupby(["email","day"]).size().reset_index(name="pv").groupby("email")["day"].nunique().reset_index(name="active_days_30d")
        days_7 = dfu[dfu["day"] >= cutoff_7].groupby(["email","day"]).size().reset_index(name="pv").groupby("email")["day"].nunique().reset_index(name="active_days_7d")
        pv_user = base.merge(days_total, on="email", how="left").merge(days_30, on="email", how="left").merge(days_7, on="email", how="left").fillna(0)
        # é€£ç¶šæ—¥æ•°ï¼ˆcurrent / longestï¼‰
        def calc_streaks(days):
            if not len(days):
                return 0, 0
            days = sorted(set(days))
            longest = cur = 1
            for i in range(1, len(days)):
                if (days[i] - days[i-1]).days == 1:
                    cur += 1
                    longest = max(longest, cur)
                else:
                    cur = 1
            # ç¾åœ¨ã®é€£ç¶šï¼ˆæ—¥ä»˜æœ«å°¾ã‹ã‚‰é€†æ–¹å‘ï¼‰
            cur_now = 1
            for i in range(len(days)-1, 0, -1):
                if (days[i] - days[i-1]).days == 1:
                    cur_now += 1
                else:
                    break
            return cur_now, longest
        def streak_metrics(s: pd.Series) -> pd.Series:
            cur, longest = calc_streaks(pd.to_datetime(s).dt.date.tolist())
            return pd.Series({"current_streak_days": cur, "longest_streak_days": longest})
        streaks = dfu.groupby("email")["day"].apply(streak_metrics).reset_index()
        pv_user = pv_user.merge(streaks, on="email", how="left")
        # å‹ãƒ»æ¬ æè£œå®Œ
        for col in ["pv_total","active_days_total","active_days_30d","active_days_7d","current_streak_days","longest_streak_days"]:
            if col not in pv_user.columns:
                pv_user[col] = 0
        pv_user = to_numeric(pv_user, ["pv_total","active_days_total","active_days_30d","active_days_7d","current_streak_days","longest_streak_days"])
        if "first_seen" not in pv_user.columns:
            pv_user["first_seen"] = pd.NaT
        if "last_seen" not in pv_user.columns:
            pv_user["last_seen"] = pd.NaT
    # åˆ†å¸ƒï¼ˆç›´è¿‘30æ—¥ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ—¥æ•°ï¼‰: å†é›†è¨ˆã«åŸºã¥ã
    if not pv_user.empty:
        st.markdown("#### åˆ†å¸ƒï¼ˆç›´è¿‘30æ—¥ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ—¥æ•°ï¼‰")
        hist = alt.Chart(pv_user).mark_bar().encode(
            x=alt.X("active_days_30d:Q", bin=alt.Bin(maxbins=30), title="Active Days (30d)"),
            y=alt.Y("count()", title="Users"),
        ).properties(height=360)
        st.altair_chart(hist, use_container_width=True)
        # page_views ç”±æ¥ã®æŒ‡æ¨™ï¼ˆç·PVã«åŸºã¥ãï¼‰
        st.markdown("#### page_views ç”±æ¥ã®æŒ‡æ¨™")
        cols = st.columns(3)
        with cols[0]:
            st.metric("ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", f"{len(pv_user):,}")
        with cols[1]:
            st.metric("å¹³å‡ãƒ­ã‚°ã‚¤ãƒ³å›æ•°ï¼ˆç·PVï¼‰", f"{pv_user['pv_total'].mean():.1f}")
        with cols[2]:
            st.metric("ä¸­å¤®å€¤ï¼ˆç·PVï¼‰", f"{pv_user['pv_total'].median():.0f}")
        thr_max = int(max(1, pv_user["pv_total"].max()))
        thr = st.slider("ã—ãã„å€¤ï¼ˆç·PVãŒä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰", 1, thr_max, min(10, thr_max), key="pv_total_threshold")
        cohort = pv_user[pv_user["pv_total"] >= thr].copy().sort_values("pv_total", ascending=False)
        st.write(f"è©²å½“ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(cohort)} äºº / ã—ãã„å€¤: {thr} å›ä»¥ä¸Š")
        with st.expander("è©²å½“ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆã‚³ãƒ”ãƒ¼ç”¨ï¼‰", expanded=False):
            emails_text = "\n".join(cohort["email"].astype(str).tolist())
            st.text_area("Emails", emails_text, height=180)
        with st.expander("è©²å½“ãƒ¦ãƒ¼ã‚¶ãƒ¼è©³ç´°", expanded=False):
            st.dataframe(cohort[["email","pv_total","active_days_total","active_days_30d","current_streak_days","longest_streak_days","first_seen","last_seen"]],
                         use_container_width=True, height=360)
    # å…¨ä½“ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¯éè¡¨ç¤ºï¼ˆè¦æœ›ã«ã‚ˆã‚Šå‰Šé™¤ï¼‰
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥: æ—¥æ™‚ãƒã‚±ãƒƒãƒˆ Ã— ãƒ¦ãƒ¼ã‚¶ãƒ¼ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆç¸¦=ãƒ¦ãƒ¼ã‚¶ãƒ¼, æ¨ª=æ™‚ç³»åˆ—ï¼‰
    if not pv_raw.empty:
        st.markdown("#### ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— æ™‚ç³»åˆ— ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆç¸¦=ãƒ¦ãƒ¼ã‚¶ãƒ¼, æ¨ª=æ—¥ä»˜æ™‚åˆ»ï¼‰")
        days_back = st.slider("å¯¾è±¡æœŸé–“ï¼ˆæ—¥ï¼‰", 7, 180, 60, key="pv_user_time_days")
        topn = st.slider("è¡¨ç¤ºãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ï¼ˆä¸Šä½PVï¼‰", 10, 100, 40, step=5, key="pv_user_time_topn")
        res_label = st.select_slider("æ™‚é–“è§£åƒåº¦", options=["15åˆ†", "30åˆ†", "1æ™‚é–“", "3æ™‚é–“", "6æ™‚é–“", "12æ™‚é–“"], value="1æ™‚é–“", key="pv_user_time_res")
        # pandas 2.2+ ã¯ 'H' ãŒéæ¨å¥¨ã®ãŸã‚å°æ–‡å­—ã¸
        freq_map = {"15åˆ†":"15min", "30åˆ†":"30min", "1æ™‚é–“":"1h", "3æ™‚é–“":"3h", "6æ™‚é–“":"6h", "12æ™‚é–“":"12h"}
        freq = freq_map.get(res_label, "1h")
        df = pv_raw.copy()
        df["email"] = df.get("email", "").astype(str).map(normalize_email)
        # ç„¡åŠ¹ãƒ¡ãƒ¼ãƒ«é™¤å¤–ï¼ˆadmin/ç©º/nanï¼‰
        df = df[df["email"].str.contains("@", na=False)]
        df = df[~df["email"].apply(is_admin_email)]
        df["created_at"] = parse_date(df.get("created_at"))
        df = df.dropna(subset=["created_at"])
        cutoff = pd.Timestamp.now() - pd.Timedelta(days=days_back)
        df = df[df["created_at"] >= cutoff]
        # è§£åƒåº¦ã§ãƒã‚±ãƒƒãƒˆ
        df["bucket"] = df["created_at"].dt.floor(freq)
        # ä¸Šä½ãƒ¦ãƒ¼ã‚¶ãƒ¼æŠ½å‡ºï¼ˆæœŸé–“å†…PVä¸Šä½ï¼‰ + ä¸Šé™ã‚’å®Ÿãƒ‡ãƒ¼ã‚¿æ•°ã«åˆã‚ã›ã‚‹
        unique_emails = df["email"].unique().tolist()
        topn_eff = min(topn, len(unique_emails))
        tops = df.groupby("email").size().reset_index(name="pv").sort_values("pv", ascending=False).head(topn_eff)["email"]
        df = df[df["email"].isin(tops)]
        # ä¸¦ã³é †ï¼ˆç·PVé™é †ï¼‰
        totals = df.groupby("email").size().sort_values(ascending=False)
        email_order = totals.index.tolist()
        # ãƒ”ãƒœãƒƒãƒˆï¼ˆæ—¥ä»˜æ™‚åˆ» Ã— ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰: presence(1/0) ã‚’è‰²ã«ã—ã¦ã€Œè‰²ãŒä»˜ã„ã¦ã„ãŸã‚‰æ¥è¨ªã€
        # å®Œå…¨ã‚°ãƒªãƒƒãƒ‰åŒ–ï¼ˆæœªè¨ªã‚‚0ã§æç”»ï¼‰
        full_buckets = pd.date_range(start=df["bucket"].min(), end=df["bucket"].max(), freq=freq)
        users_sel = pd.Index(email_order, name="email")
        grid = pd.MultiIndex.from_product([users_sel, full_buckets], names=["email","bucket"]).to_frame(index=False)
        pivot = df.groupby(["email","bucket"]).size().reset_index(name="pv")
        pivot = grid.merge(pivot, on=["email","bucket"], how="left").fillna({"pv": 0})
        pivot["present"] = (pivot["pv"] > 0).astype(int)
        # é›¢æ•£ãƒ©ãƒ™ãƒ«ã§æ¨ªè»¸ã‚’æ˜ç¤ºï¼ˆé€£ç¶šè»¸ã§é–“å¼•ã‹ã‚Œã‚‹ã®ã‚’é˜²ãï¼‰
        pivot["bucket_str"] = pivot["bucket"].dt.strftime("%Y-%m-%d %H:%M")
        bucket_order = pivot["bucket_str"].drop_duplicates().sort_values().tolist()
        heat = alt.Chart(pivot).mark_rect(stroke=None).encode(
            x=alt.X("bucket_str:N",
                    sort=bucket_order,
                    title=f"æ™‚åˆ»ï¼ˆ{res_label}ãƒã‚±ãƒƒãƒˆï¼‰",
                    axis=alt.Axis(labelAngle=-45, labelOverlap=False, labelLimit=1000)),
            y=alt.Y("email:N",
                    title="ãƒ¦ãƒ¼ã‚¶ãƒ¼",
                    sort=email_order,
                    axis=alt.Axis(labelLimit=1000, labelOverlap=False, labelFontSize=10)),
            color=alt.Color("present:Q",
                            title="åœ¨å¸­",
                            scale=alt.Scale(domain=[0,1], range=["#f3f4f6", "#10b981"])),
            tooltip=[alt.Tooltip("email:N", title="ãƒ¦ãƒ¼ã‚¶ãƒ¼"),
                     alt.Tooltip("bucket:T", title="æ™‚åˆ»"),
                     alt.Tooltip("pv:Q", title="PV")],
        ).properties(height=max(360, len(email_order)*16))
        st.altair_chart(heat, use_container_width=True)
        st.caption(f"è¡¨ç¤ºä¸­: {len(email_order)} ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆä¸Šé™ {topn}ï¼‰ / æœŸé–“: éå» {days_back} æ—¥ / è§£åƒåº¦: {res_label}")
    # æŠ•ç¨¿â†’åˆè¿”ä¿¡ã¾ã§ã®æ™‚é–“ï¼ˆåˆ†ï¼‰ã®åˆ†å¸ƒ
    if not posts_raw.empty and not replies_raw.empty:
        with st.expander("æŠ•ç¨¿â†’åˆè¿”ä¿¡ã¾ã§ã®æ™‚é–“ï¼ˆåˆ†ï¼‰", expanded=False):
            p = posts_raw[["id","created_at"]].copy()
            p["post_ts"] = parse_date(p["created_at"])
            r = replies_raw[["post_id","created_at"]].copy()
            r["reply_ts"] = parse_date(r["created_at"])
            first_r = r.sort_values("reply_ts").dropna(subset=["reply_ts"]).groupby("post_id").first().reset_index()
            merged = p.merge(first_r, left_on="id", right_on="post_id", how="inner")
            merged["mins"] = (merged["reply_ts"] - merged["post_ts"]).dt.total_seconds() / 60.0
            merged = merged[(merged["mins"] >= 0) & (merged["mins"].notna())]
            hist = alt.Chart(merged).mark_bar().encode(
                x=alt.X("mins:Q", bin=alt.Bin(maxbins=50), title="çµŒéæ™‚é–“ï¼ˆåˆ†ï¼‰"),
                y=alt.Y("count()", title="æŠ•ç¨¿æ•°"),
                tooltip=["count()"]
            ).properties(height=240)
            st.altair_chart(hist, use_container_width=True)
    # ä¸‹éƒ¨ã«ãƒ‡ãƒ¼ã‚¿ä¸€è¦§
    with st.expander("ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆpage_views ç”±æ¥ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼é›†è¨ˆï¼‰", expanded=False):
        if not pv_user.empty:
            show_cols = ["email","pv_total","active_days_total","active_days_30d","active_days_7d","current_streak_days","longest_streak_days","first_seen","last_seen"]
            display = pv_user[show_cols].sort_values(["active_days_30d","current_streak_days","pv_total"], ascending=[False, False, False])
            st.dataframe(display, use_container_width=True, height=420)
        else:
            st.info("page_views.csv ãŒç©ºã€ã¾ãŸã¯æœ‰åŠ¹ãªãƒ¡ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

def admins_tab():
    st.subheader("ç®¡ç†è€…ã®æ‹…å½“è€…åˆ¥ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£")
    users_full = load_csv(AGG_DIR / "users_full_summary.csv")
    if users_full.empty:
        st.info("users_full_summary.csv ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    admins = users_full[users_full["email"].astype(str).apply(is_admin_email)].copy()
    if admins.empty:
        st.info("ç®¡ç†è€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    # ã‚°ãƒ«ãƒ¼ãƒ—åˆ—ã‚’ä»˜ä¸
    admins["group"] = admins["email"].astype(str).apply(admin_group)
    admins = admins.dropna(subset=["group"])
    metrics = ["board_posts","board_replies","market_items","course_summaries","circle_summaries"]
    admins = to_numeric(admins, metrics)
    grouped = admins.groupby("group", as_index=False)[metrics].sum()
    st.dataframe(grouped.sort_values("group"), use_container_width=True, height=300)
    # ãƒãƒ£ãƒ¼ãƒˆï¼ˆç¸¦ã«ã‚¿ãƒ–ã§åˆ‡æ›¿ï¼‰
    tabs = st.tabs(["æ²ç¤ºæ¿æŠ•ç¨¿","æ²ç¤ºæ¿è¿”ä¿¡","ãƒãƒ¼ã‚±ãƒƒãƒˆå‡ºå“","æˆæ¥­ã¾ã¨ã‚æŠ•ç¨¿","ã‚µãƒ¼ã‚¯ãƒ«ã¾ã¨ã‚æŠ•ç¨¿"])
    titles = [
        ("board_posts","æ²ç¤ºæ¿æŠ•ç¨¿"),
        ("board_replies","æ²ç¤ºæ¿è¿”ä¿¡"),
        ("market_items","ãƒãƒ¼ã‚±ãƒƒãƒˆå‡ºå“"),
        ("course_summaries","æˆæ¥­ã¾ã¨ã‚æŠ•ç¨¿"),
        ("circle_summaries","ã‚µãƒ¼ã‚¯ãƒ«ã¾ã¨ã‚æŠ•ç¨¿"),
    ]
    for i, (col, ttl) in enumerate(titles):
        with tabs[i]:
            chart = alt.Chart(grouped).mark_bar().encode(
                x=alt.X("group:N", title="æ‹…å½“è€…ã‚°ãƒ«ãƒ¼ãƒ—"),
                y=alt.Y(f"{col}:Q", title=ttl),
                tooltip=list(grouped.columns),
            ).properties(height=260)
            st.altair_chart(chart, use_container_width=True)

def main():
    st.set_page_config(page_title="URIV Analytics", page_icon="ğŸ“Š", layout="wide")
    ensure_dirs()

    st.sidebar.title("ãƒ‡ãƒ¼ã‚¿æ“ä½œ")
    if st.sidebar.button("æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦é›†è¨ˆ", type="primary", use_container_width=True):
        with st.spinner("å–å¾—ãƒ»é›†è¨ˆä¸­..."):
            run_fetch()
        st.success("æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ã—ã¾ã—ãŸã€‚")
        st.rerun()

    tab_names = ["Overview", "Users", "Boards", "Market", "Engagement", "Admins"]
    tabs = st.tabs(tab_names)
    with tabs[0]:
        overview_tab()
    with tabs[1]:
        users_tab()
    with tabs[2]:
        boards_tab()
    with tabs[3]:
        market_tab()
    with tabs[4]:
        engagement_tab()
    with tabs[5]:
        admins_tab()

if __name__ == "__main__":
    main()

